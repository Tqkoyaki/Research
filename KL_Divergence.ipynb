{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3    9.3\n",
       "3    151.5   41.3       58.5   18.5\n",
       "4    180.8   10.8       58.4   12.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1    9.7\n",
       "197  177.0    9.3        6.4   12.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Obtains the file and cleans it\n",
    "FILE_PATH = 'data/Advertising.csv' \n",
    "df = pd.read_csv(FILE_PATH).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Obtains our x and y vectors\n",
    "x = df.TV.to_numpy()\n",
    "y = df.Sales.to_numpy()\n",
    "\n",
    "# Displays the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "class KL_Divergence(nn.Module):\n",
    "    def __init__(self, rand_size=100):\n",
    "        super().__init__()\n",
    "\n",
    "        # The parameters needed to do divergence\n",
    "        self.mu_m = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "        self.sig_m = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "        self.mu_b = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "        self.sig_b = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "        self.noise = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "        \n",
    "        # The size parameter used for random generation\n",
    "        self.rand_size = rand_size\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        # Randomly generated slope and intercept\n",
    "        m = torch.normal(self.mu_m.item(), self.sig_m.item(), (self.rand_size,))\n",
    "        b = torch.normal(self.mu_b.item(), self.sig_b.item(), (self.rand_size,))\n",
    "        \n",
    "        # Gets a list of values to sum\n",
    "        res = [self.log_q(m[j], b[j]) - self.log_p(m[j], b[j], x, y) for j in range(len(m))]\n",
    "        \n",
    "        # Returns the sum of the values\n",
    "        return torch.sum(torch.Tensor(res))\n",
    "    \n",
    "        \n",
    "    def log_q(self, m_j, b_j):\n",
    "        # Calculates the log_q for each m_j and b_j\n",
    "        log_m = -((m_j - self.mu_m) ** 2 / 2 * self.sig_m ** 2 + 0.5 * torch.log(self.sig_m ** 2))\n",
    "        log_b = -((b_j - self.mu_b) ** 2 / 2 * self.sig_b ** 2 + 0.5 * torch.log(self.sig_b ** 2))\n",
    "        return log_m + log_b\n",
    "    \n",
    "    def log_p(self, m_j, b_j, x, y):\n",
    "        # Calculates the log_p for each m_j and b_j\n",
    "        vals = [(y[i] - x[i] * m_j - b_j) ** 2 / 2 * self.noise ** 2 + 0.5 * torch.log(self.noise ** 2) for i in range(len(x))]\n",
    "        return torch.sum(torch.Tensor(vals)) + (m_j ** 2 / 2 + b_j ** 2 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the specific model\n",
    "def kl_train(x, y, rand_size=100, model=None, epochs=5, frac=0.1):\n",
    "    if model == None:\n",
    "        model = KL_Divergence(rand_size=100)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training...\"):\n",
    "        # Zeros gradiant for training\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Random selection of data points per iteration\n",
    "        indices = torch.randint(low=0, high=110, size=(int(len(x) * 0.1), 1))\n",
    "        \n",
    "        # Calculates likelihood\n",
    "        loglik = model(x[indices], y[indices])\n",
    "        #loglik = model(x, y)\n",
    "        \n",
    "        # Mean of loglik\n",
    "        e = -torch.mean(loglik)\n",
    "        \n",
    "        # Updates parameters\n",
    "        e.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_kl \u001b[39m=\u001b[39m kl_train(x, y)\n",
      "Cell \u001b[1;32mIn[43], line 22\u001b[0m, in \u001b[0;36mkl_train\u001b[1;34m(x, y, rand_size, model, epochs, frac)\u001b[0m\n\u001b[0;32m     19\u001b[0m     e \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39mmean(loglik)\n\u001b[0;32m     21\u001b[0m     \u001b[39m# Updates parameters\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     e\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     23\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "model_kl = kl_train(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(x):\n",
    "    print(x)\n",
    "    return 1\n",
    "\n",
    "vals = torch.Tensor([[1, 2, 3, 4, 5], [2, 3, 4, 5, 6]])\n",
    "vals.apply_(func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
