{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 4, 6]])\n",
      "tensor([[2, 4, 4],\n",
      "        [3, 6, 7]])\n",
      "tensor([[ 1,  1],\n",
      "        [-1, -2],\n",
      "        [-1, -3]])\n",
      "tensor([[ 1,  1],\n",
      "        [-1, -2],\n",
      "        [-1, -3]])\n",
      "tensor([ 2, -3, -4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pande\\AppData\\Local\\Temp\\ipykernel_5796\\3177086203.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x = torch.tensor(torch.tensor([1, 2]))\n"
     ]
    }
   ],
   "source": [
    "m = torch.tensor([1, 2, 3])\n",
    "x = torch.tensor([1, 2])\n",
    "b = torch.tensor([1, 2, 1])\n",
    "# y = torch.tensor([3, 4])\n",
    "x = torch.tensor(np.array([1, 2]))\n",
    "y = torch.tensor(np.array([3, 4]))\n",
    "\n",
    "mx = torch.einsum('m,x -> xm', m, x)\n",
    "mxb = mx + b\n",
    "print(mx)\n",
    "print(mxb)\n",
    "print(y - mxb.transpose(0, 1))\n",
    "print((y - mxb.transpose(0, 1)))\n",
    "print((y - mxb.transpose(0, 1)).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distribution(nn.Module):\n",
    "    def __init__(self, size=1000):\n",
    "        super().__init__()\n",
    "        self.mu = nn.Parameter(torch.tensor(0.0), requires_grad=True)\n",
    "        self.std = nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "        self.size = size\n",
    "    def forward(self):\n",
    "        return self.mu + self.std * torch.normal(0, 1, size=(1, self.size))\n",
    "\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, size=1000):\n",
    "        super().__init__()\n",
    "        self.m = Distribution(size=size)\n",
    "        self.b = Distribution(size=size)\n",
    "    def forward(self, x, y):\n",
    "        m = self.m()\n",
    "        b = self.b()\n",
    "        \n",
    "        def loss(x_i, y_i, m_j, b_j):\n",
    "            return (y_i - (m_j * x_i - b_j)) ** 2\n",
    "\n",
    "        def loss_val(x_i, y_i):\n",
    "            vals = np.vectorize(loss)(x_i, y_i, m, b)\n",
    "            return (1 / len(m)) * np.sum(vals)\n",
    "    \n",
    "        vals = np.vectorize(loss_val)(x, y)\n",
    "        total_loss = np.sum(vals) * (1/ len(x))\n",
    "        \n",
    "        # Minimize loss by maximizing this value\n",
    "        return torch.tensor((total_loss), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(x, y, epochs=5):\n",
    "    model = LinearRegression()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training...\"):\n",
    "        # Zeros gradiant for training\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Calculates likelihood\n",
    "        loglik = model(x, y)\n",
    "        e = torch.mean(loglik)\n",
    "        \n",
    "        # Updates parameters\n",
    "        e.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  Radio  Newspaper  Sales\n",
       "0    230.1   37.8       69.2   22.1\n",
       "1     44.5   39.3       45.1   10.4\n",
       "2     17.2   45.9       69.3    9.3\n",
       "3    151.5   41.3       58.5   18.5\n",
       "4    180.8   10.8       58.4   12.9\n",
       "..     ...    ...        ...    ...\n",
       "195   38.2    3.7       13.8    7.6\n",
       "196   94.2    4.9        8.1    9.7\n",
       "197  177.0    9.3        6.4   12.8\n",
       "198  283.6   42.0       66.2   25.5\n",
       "199  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/Advertising.csv').drop('Unnamed: 0', axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.TV.to_numpy()\n",
    "y = df.Sales.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res \u001b[39m=\u001b[39m training(x, y, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m res\n",
      "Cell \u001b[1;32mIn[108], line 10\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(x, y, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m      9\u001b[0m \u001b[39m# Calculates likelihood\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m loglik \u001b[39m=\u001b[39m model(x, y)\n\u001b[0;32m     11\u001b[0m e \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(loglik)\n\u001b[0;32m     13\u001b[0m \u001b[39m# Updates parameters\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[107], line 27\u001b[0m, in \u001b[0;36mLinearRegression.forward\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     24\u001b[0m     vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvectorize(loss)(x_i, y_i, m, b)\n\u001b[0;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(m)) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(vals)\n\u001b[1;32m---> 27\u001b[0m vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvectorize(loss_val)(x, y)\n\u001b[0;32m     28\u001b[0m total_loss \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(vals) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m\u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(x))\n\u001b[0;32m     30\u001b[0m \u001b[39m# Minimize loss by maximizing this value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2328\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2325\u001b[0m     vargs \u001b[39m=\u001b[39m [args[_i] \u001b[39mfor\u001b[39;00m _i \u001b[39min\u001b[39;00m inds]\n\u001b[0;32m   2326\u001b[0m     vargs\u001b[39m.\u001b[39mextend([kwargs[_n] \u001b[39mfor\u001b[39;00m _n \u001b[39min\u001b[39;00m names])\n\u001b[1;32m-> 2328\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize_call(func\u001b[39m=\u001b[39;49mfunc, args\u001b[39m=\u001b[39;49mvargs)\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2406\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2404\u001b[0m     res \u001b[39m=\u001b[39m func()\n\u001b[0;32m   2405\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2406\u001b[0m     ufunc, otypes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_ufunc_and_otypes(func\u001b[39m=\u001b[39;49mfunc, args\u001b[39m=\u001b[39;49margs)\n\u001b[0;32m   2408\u001b[0m     \u001b[39m# Convert args to object arrays first\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     inputs \u001b[39m=\u001b[39m [asanyarray(a, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2366\u001b[0m, in \u001b[0;36mvectorize._get_ufunc_and_otypes\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2362\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcannot call `vectorize` on size 0 inputs \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2363\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39munless `otypes` is set\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   2365\u001b[0m inputs \u001b[39m=\u001b[39m [arg\u001b[39m.\u001b[39mflat[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args]\n\u001b[1;32m-> 2366\u001b[0m outputs \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49minputs)\n\u001b[0;32m   2368\u001b[0m \u001b[39m# Performance note: profiling indicates that -- for simple\u001b[39;00m\n\u001b[0;32m   2369\u001b[0m \u001b[39m# functions at least -- this wrapping can almost double the\u001b[39;00m\n\u001b[0;32m   2370\u001b[0m \u001b[39m# execution time.\u001b[39;00m\n\u001b[0;32m   2371\u001b[0m \u001b[39m# Hence we make it optional.\u001b[39;00m\n\u001b[0;32m   2372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache:\n",
      "Cell \u001b[1;32mIn[107], line 24\u001b[0m, in \u001b[0;36mLinearRegression.forward.<locals>.loss_val\u001b[1;34m(x_i, y_i)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_val\u001b[39m(x_i, y_i):\n\u001b[1;32m---> 24\u001b[0m     vals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mvectorize(loss)(x_i, y_i, m, b)\n\u001b[0;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39m1\u001b[39m \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(m)) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(vals)\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2328\u001b[0m, in \u001b[0;36mvectorize.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2325\u001b[0m     vargs \u001b[39m=\u001b[39m [args[_i] \u001b[39mfor\u001b[39;00m _i \u001b[39min\u001b[39;00m inds]\n\u001b[0;32m   2326\u001b[0m     vargs\u001b[39m.\u001b[39mextend([kwargs[_n] \u001b[39mfor\u001b[39;00m _n \u001b[39min\u001b[39;00m names])\n\u001b[1;32m-> 2328\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vectorize_call(func\u001b[39m=\u001b[39;49mfunc, args\u001b[39m=\u001b[39;49mvargs)\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2406\u001b[0m, in \u001b[0;36mvectorize._vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2404\u001b[0m     res \u001b[39m=\u001b[39m func()\n\u001b[0;32m   2405\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2406\u001b[0m     ufunc, otypes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_ufunc_and_otypes(func\u001b[39m=\u001b[39;49mfunc, args\u001b[39m=\u001b[39;49margs)\n\u001b[0;32m   2408\u001b[0m     \u001b[39m# Convert args to object arrays first\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     inputs \u001b[39m=\u001b[39m [asanyarray(a, dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m args]\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2360\u001b[0m, in \u001b[0;36mvectorize._get_ufunc_and_otypes\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2353\u001b[0m         ufunc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ufunc\u001b[39m.\u001b[39msetdefault(nin, ufunc)\n\u001b[0;32m   2354\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2355\u001b[0m     \u001b[39m# Get number of outputs and output types by calling the function on\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m     \u001b[39m# the first entries of args.  We also cache the result to prevent\u001b[39;00m\n\u001b[0;32m   2357\u001b[0m     \u001b[39m# the subsequent call when the ufunc is evaluated.\u001b[39;00m\n\u001b[0;32m   2358\u001b[0m     \u001b[39m# Assumes that ufunc first evaluates the 0th elements in the input\u001b[39;00m\n\u001b[0;32m   2359\u001b[0m     \u001b[39m# arrays (the input values are not checked to ensure this)\u001b[39;00m\n\u001b[1;32m-> 2360\u001b[0m     args \u001b[39m=\u001b[39m [asarray(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args]\n\u001b[0;32m   2361\u001b[0m     \u001b[39mif\u001b[39;00m builtins\u001b[39m.\u001b[39many(arg\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args):\n\u001b[0;32m   2362\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcannot call `vectorize` on size 0 inputs \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2363\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39munless `otypes` is set\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\function_base.py:2360\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2353\u001b[0m         ufunc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ufunc\u001b[39m.\u001b[39msetdefault(nin, ufunc)\n\u001b[0;32m   2354\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2355\u001b[0m     \u001b[39m# Get number of outputs and output types by calling the function on\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m     \u001b[39m# the first entries of args.  We also cache the result to prevent\u001b[39;00m\n\u001b[0;32m   2357\u001b[0m     \u001b[39m# the subsequent call when the ufunc is evaluated.\u001b[39;00m\n\u001b[0;32m   2358\u001b[0m     \u001b[39m# Assumes that ufunc first evaluates the 0th elements in the input\u001b[39;00m\n\u001b[0;32m   2359\u001b[0m     \u001b[39m# arrays (the input values are not checked to ensure this)\u001b[39;00m\n\u001b[1;32m-> 2360\u001b[0m     args \u001b[39m=\u001b[39m [asarray(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args]\n\u001b[0;32m   2361\u001b[0m     \u001b[39mif\u001b[39;00m builtins\u001b[39m.\u001b[39many(arg\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args):\n\u001b[0;32m   2362\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcannot call `vectorize` on size 0 inputs \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2363\u001b[0m                          \u001b[39m'\u001b[39m\u001b[39munless `otypes` is set\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pande\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_tensor.py:955\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    953\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    954\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    956\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    957\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "res = training(x, y, epochs=10)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor(0., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(res.m.mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor(1., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(res.m.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor(0., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(res.b.mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor(1., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(res.b.std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
